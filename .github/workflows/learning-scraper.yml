name: Learning Scraper

on:
  repository_dispatch:
    types: [scrape_request]
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to scrape'
        required: true
        default: 'https://example.com'
      priority:
        description: 'Task priority'
        required: false
        default: 'normal'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install requests beautifulsoup4 python-dotenv
    
    - name: Create directories
      run: |
        mkdir -p screenshots
        mkdir -p logs
    
    - name: Run reliable scraper
      env:
        SYNAPSE_HUB_URL: ${{ secrets.SYNAPSE_HUB_URL }}
        SENSORY_API_KEY: ${{ secrets.SENSORY_API_KEY }}
        TARGET_URL: ${{ github.event.client_payload.url || github.event.inputs.url }}
        PRIORITY: ${{ github.event.client_payload.priority || github.event.inputs.priority }}
      run: |
        echo "üß† Starting Reliable Sensory Neurons..."
        python scraper.py
        echo "‚úÖ Scraper completed"
        
        echo "üìÅ Files created:"
        ls -la screenshots/
        ls -la results.json
    
    - name: Upload results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraping-results-${{ github.run_id }}
        path: |
          screenshots/
          results.json
          logs/
        retention-days: 3
        if-no-files-found: warn
