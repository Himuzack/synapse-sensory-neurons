name: Learning Scraper

on:
  repository_dispatch:
    types: [scrape_request]
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to scrape'
        required: true
        default: 'https://example.com'
      priority:
        description: 'Task priority'
        required: false
        default: 'normal'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Install Playwright browsers
      run: |
        playwright install chromium
        playwright install-deps
    
    - name: Create directories
      run: |
        mkdir -p screenshots
        mkdir -p logs
    
    - name: Run learning scraper
      env:
        SYNAPSE_HUB_URL: ${{ secrets.SYNAPSE_HUB_URL }}
        SENSORY_API_KEY: ${{ secrets.SENSORY_API_KEY }}
        TARGET_URL: ${{ github.event.client_payload.url || github.event.inputs.url }}
        PRIORITY: ${{ github.event.client_payload.priority || github.event.inputs.priority }}
      run: |
        echo "ðŸ§  Starting Sensory Neurons..."
        echo "Target URL: $TARGET_URL"
        echo "Hub URL: $SYNAPSE_HUB_URL"
        python scraper.py
        echo "
